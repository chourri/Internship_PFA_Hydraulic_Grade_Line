{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed82af5e",
   "metadata": {},
   "source": [
    "# Calcul et Visualisation de la HGL (version corrigée)\n",
    "Ce notebook reprend le calcul et la visualisation de la HGL avec gestion robuste des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74361e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "g = 9.81  # gravité\n",
    "stations = {\n",
    "    'Head': {'elevation_m': 650, 'distance_km': 0},\n",
    "    'PMS1': {'elevation_m': 680, 'distance_km': 45},\n",
    "    'VANNE': {'elevation_m': 515, 'distance_km': 68},\n",
    "    'PMS2': {'elevation_m': 360, 'distance_km': 101},\n",
    "    'PMS3': {'elevation_m': 110, 'distance_km': 130},\n",
    "    'PMS4': {'elevation_m': 143, 'distance_km': 162},\n",
    "    'Terminal': {'elevation_m': 60, 'distance_km': 187}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fec7bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset fusionné\n",
    "merged_df = pd.read_csv('./new_dataset/Merged_All_Stations_updated.csv', sep=',', decimal='.', engine='python')\n",
    "for col in ['Density_HS_Average', 'Density_PMS1', 'Density_VANNE', 'Density_PMS2', 'Density_PMS3', 'Density_PMS4', 'Density_T',\n",
    "            'Pressure_HS_Average', 'Pressure_PMS1', 'Pressure_VANNE', 'Pressure_PMS2', 'Pressure_PMS3', 'Pressure_PMS4', 'Pressure_T']:\n",
    "    if col in merged_df.columns:\n",
    "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66146aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_crossings = [\n",
    "    {'start_km': 60, 'end_km': 65, 'water_elev_m': 1150},\n",
    "    {'start_km': 150, 'end_km': 152, 'water_elev_m': 1080},\n",
    "]\n",
    "def adjust_elevation(distance, base_elevation, river_crossings):\n",
    "    for river in river_crossings:\n",
    "        if river['start_km'] <= distance <= river['end_km']:\n",
    "            return river['water_elev_m']\n",
    "    return base_elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03c6bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_HGL(row, station):\n",
    "    stations_columns = {\n",
    "        'Head': 'HS',\n",
    "        'PMS1': 'PMS1',\n",
    "        'VANNE': 'VANNE',\n",
    "        'PMS2': 'PMS2',\n",
    "        'PMS3': 'PMS3',\n",
    "        'PMS4': 'PMS4',\n",
    "        'Terminal': 'T'\n",
    "    }\n",
    "    prefix = stations_columns[station]\n",
    "    P_col = f'Pressure_{prefix}' if prefix != 'HS' else 'Pressure_HS_Average'\n",
    "    rho_col = f'Density_{prefix}' if prefix != 'HS' else 'Density_HS_Average'\n",
    "    P = row.get(P_col, None)\n",
    "    rho = row.get(rho_col, None)\n",
    "    if pd.isna(P) or pd.isna(rho):\n",
    "        return None\n",
    "    P = P * 1e5\n",
    "    dist = stations[station]['distance_km']\n",
    "    z = stations[station]['elevation_m']\n",
    "    z_adjusted = adjust_elevation(dist, z, river_crossings)\n",
    "    return ((P * 0.10197) / (rho * g)) + z_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fbc8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in stations:\n",
    "    merged_df[f'HGL_{station}'] = merged_df.apply(lambda row: calculate_HGL(row, station), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5425e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"./new_dataset/HGL_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfa1b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_utils.py - TensorFlow Version: 2.16.2\n",
      "model_utils.py - Keras Version: 3.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"model_utils.py - TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"model_utils.py - Keras Version: {tf.keras.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
