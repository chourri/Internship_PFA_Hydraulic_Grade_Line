{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 12:46:41.372159: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_utils.py - TensorFlow Version: 2.16.2\n",
      "model_utils.py - Keras Version: 3.10.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'FILE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m     plot_comparison_metrics(results)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Main function to run the entire experiment.\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# --- Prepare data once ---\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X_train, X_test, Y_train, Y_test, scaler_Y \u001b[38;5;241m=\u001b[39m load_and_prepare_data(\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mFILE_PATH\u001b[49m, FEATURES, TARGETS, TIME_STEPS, TEST_SIZE\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# --- Define models to train ---\u001b[39;00m\n\u001b[1;32m     14\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m: build_lstm_model,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRU\u001b[39m\u001b[38;5;124m\"\u001b[39m: build_gru_model,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTCN\u001b[39m\u001b[38;5;124m\"\u001b[39m: build_tcn_model\n\u001b[1;32m     18\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FILE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 6. MAIN EXPERIMENT EXECUTION\n",
    "# ===================================================================\n",
    "\n",
    "from model_utils import load_and_prepare_data\n",
    "def run_experiment():\n",
    "    \"\"\"Main function to run the entire experiment.\"\"\"\n",
    "    # --- Prepare data once ---\n",
    "    X_train, X_test, Y_train, Y_test, scaler_Y = load_and_prepare_data(\n",
    "        FILE_PATH, FEATURES, TARGETS, TIME_STEPS, TEST_SIZE\n",
    "    )\n",
    "\n",
    "    # --- Define models to train ---\n",
    "    models = {\n",
    "        \"LSTM\": build_lstm_model,\n",
    "        \"GRU\": build_gru_model,\n",
    "        \"TCN\": build_tcn_model\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    output_size = len(TARGETS)\n",
    "    Y_test_original = scaler_Y.inverse_transform(Y_test)\n",
    "\n",
    "    # --- Loop through each model to train and evaluate ---\n",
    "    for name, build_func in models.items():\n",
    "        print(f\"\\n{'='*20} Training {name} Model {'='*20}\")\n",
    "        model = build_func(input_shape, output_size)\n",
    "        model.summary()\n",
    "\n",
    "        model.fit(\n",
    "            X_train, Y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Sauvegarder le mod√®le apr√®s l'entra√Ænement\n",
    "        import os\n",
    "        os.makedirs(\"saved_models\", exist_ok=True)\n",
    "        if name in [\"LSTM\", \"GRU\"]:\n",
    "            model.save(f\"saved_models/{name}_model.h5\")\n",
    "            print(f\"Mod√®le {name} sauvegard√© dans saved_models/{name}_model.h5\")\n",
    "        elif name == \"TCN\":\n",
    "            model.save_weights(f\"saved_models/{name}.weights.h5\")\n",
    "            print(f\"Poids du mod√®le TCN sauvegard√©s dans saved_models/{name}.weights.h5\")\n",
    "\n",
    "        Y_pred_scaled = model.predict(X_test)\n",
    "        Y_pred = scaler_Y.inverse_transform(Y_pred_scaled)\n",
    "        \n",
    "        mse = mean_squared_error(Y_test_original, Y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(Y_test_original, Y_pred)\n",
    "        r2 = r2_score(Y_test_original, Y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R2\": r2\n",
    "        }\n",
    "\n",
    "        print(f\"\\nüìä Regression Metrics for {name}\")\n",
    "        print(f\"MSE : {mse:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE : {mae:.4f}\")\n",
    "        print(f\"R¬≤  : {r2:.4f}\")\n",
    "        \n",
    "        # NEW FUNCTION CALL ADDED HERE\n",
    "        # Plot the first curve from the test set for this model\n",
    "        print(f\"Displaying example curve for {name} model...\")\n",
    "        plot_example_curve(Y_test_original[0], Y_pred[0], name, TARGETS)\n",
    "\n",
    "    # --- Print final results summary ---\n",
    "    print(f\"\\n{'='*20} Final Results Summary {'='*20}\")\n",
    "    print(pd.DataFrame(results).T)\n",
    "\n",
    "    # --- Plot final comparison ---\n",
    "    print(\"\\nDisplaying final comparison metrics...\")\n",
    "    plot_comparison_metrics(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_experiment()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
